{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a02de5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load CSV File with Labels\n",
    "\n",
    "csv_file = \"pics_labels.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "if 'filename' not in df.columns or 'label' not in df.columns:\n",
    "    print(\"CSV file must contain 'filename' and 'label' columns.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "print(df.info())\n",
    "print(\"\\nAll Data:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "\n",
    "# Kudlit Detection Section\n",
    "\n",
    "def detect_kudlits(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return {\"top_kudlit\": 0, \"bottom_kudlit\": 0, \"cross_under\": 0}\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    height = img.shape[0]\n",
    "    top_kudlit = 0\n",
    "    bottom_kudlit = 0\n",
    "    cross_under = 0\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = w * h\n",
    "\n",
    "        if area < 150:\n",
    "            center_y = y + h // 2\n",
    "            if center_y < height * 0.3:\n",
    "                top_kudlit += 1\n",
    "            elif center_y > height * 0.7:\n",
    "                bottom_kudlit += 1\n",
    "                aspect_ratio = w / float(h)\n",
    "                if 0.8 < aspect_ratio < 1.2:\n",
    "                    cross_under += 1\n",
    "\n",
    "    return {\n",
    "        \"top_kudlit\": top_kudlit,\n",
    "        \"bottom_kudlit\": bottom_kudlit,\n",
    "        \"cross_under\": cross_under\n",
    "    }\n",
    "\n",
    "# Process all images\n",
    "image_folder = \"Dataset\"\n",
    "kudlit_data = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    image_path = os.path.join(image_folder, row['filename'])\n",
    "    kudlit_info = detect_kudlits(image_path)\n",
    "    kudlit_data.append(kudlit_info)\n",
    "\n",
    "# Merge kudlit info\n",
    "df = pd.concat([df, pd.DataFrame(kudlit_data)], axis=1)\n",
    "\n",
    "print(\"\\nData with kudlit detection:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "\n",
    "# 2. Separate Word Frequency Distribution (Horizontal Bar Plot for Single and Double Letters)\n",
    "\n",
    "# Split the words into double-lettered (with '_') and single-lettered words\n",
    "double_letters = df['label'].str.contains('_')\n",
    "single_letters = ~double_letters\n",
    "\n",
    "# Separate the data\n",
    "double_letter_counts = df[double_letters]['label'].value_counts().reset_index()\n",
    "single_letter_counts = df[single_letters]['label'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "double_letter_counts.columns = ['label', 'count']\n",
    "single_letter_counts.columns = ['label', 'count']\n",
    "\n",
    "# Sort both datasets by count for better visualization\n",
    "double_letter_counts = double_letter_counts.sort_values(by='count', ascending=True)\n",
    "single_letter_counts = single_letter_counts.sort_values(by='count', ascending=True)\n",
    "\n",
    "\n",
    "# 2.1. Plot for Double Letter Words\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=double_letter_counts, y='label', x='count', palette='viridis')\n",
    "\n",
    "plt.title(\"Baybayin Double Letter Word Frequency\", fontsize=16)\n",
    "plt.xlabel(\"Count\", fontsize=12)\n",
    "plt.ylabel(\"Double Letter Word\", fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2.2. Plot for Single Letter Words\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=single_letter_counts, y='label', x='count', palette='viridis')\n",
    "\n",
    "plt.title(\"Baybayin Single Letter Word Frequency\", fontsize=16)\n",
    "plt.xlabel(\"Count\", fontsize=12)\n",
    "plt.ylabel(\"Single Letter Word\", fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3. Baybayin Character Frequency (Grouped and Alphabetical)\n",
    "\n",
    "# Define character mapping based on the chart\n",
    "baybayin_letters = [\n",
    "    'a', 'ba', 'ka', 'da', 'ga', 'ha', 'la', 'ma', 'na', 'nga', 'pa', 'sa', 'ta', 'wa', 'ya',\n",
    "    'e_i', 'be', 'ke', 'de', 'ge', 'he', 'le', 'me', 'ne', 'nge', 'pe', 'se', 'te', 'we', 'ye',\n",
    "    'o_u', 'bo', 'ko', 'do', 'go', 'ho', 'lo', 'mo', 'no', 'ngo', 'po', 'so', 'to', 'wo', 'yo',\n",
    "    'b', 'k', 'd', 'g', 'l', 'm', 'n', 'ng', 'p', 's', 't', 'w', 'y'\n",
    "]\n",
    "\n",
    "# Flatten and normalize\n",
    "labels = df['label'].str.replace('-', '').str.split('_').explode().dropna()\n",
    "def normalize_baybayin_char(char):\n",
    "    if char in ['e', 'i']:\n",
    "        return 'e_i'\n",
    "    elif char in ['o', 'u']:\n",
    "        return 'o_u'\n",
    "    return char\n",
    "\n",
    "normalized = labels.apply(normalize_baybayin_char)\n",
    "char_counts = normalized.value_counts().to_dict()\n",
    "char_counts_complete = {char: char_counts.get(char, 0) for char in baybayin_letters}\n",
    "char_df = pd.DataFrame(list(char_counts_complete.items()), columns=['character', 'count'])\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(data=char_df, x='character', y='count', palette='crest')\n",
    "\n",
    "plt.title(\"Baybayin Character Frequency (Grouped & Alphabetical)\", fontsize=16)\n",
    "plt.xlabel(\"Character\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.suptitle(f\"Total Characters: {char_df['count'].sum()}\", fontsize=12, y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Correlation Heatmap (if image size is available)\n",
    "\n",
    "if 'image_width' in df.columns and 'image_height' in df.columns:\n",
    "    corr_matrix = df[['image_width', 'image_height']].corr()\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No image dimensions found in the CSV. Skipping the correlation heatmap.\")\n",
    "\n",
    "# 5. Kudlit Type Summary (Strict Baybayin Rules - Enhanced)\n",
    "\n",
    "# Valid sets\n",
    "top_vowel_suffixes = ['e', 'i']\n",
    "bottom_vowel_suffixes = ['o', 'u']\n",
    "cross_consonants = ['b', 'k', 'd', 'g', 'l', 'm', 'n', 'ng', 's', 't', 'w', 'y']\n",
    "no_kudlit_valid = ['a', 'ba', 'ka', 'da', 'ga', 'ha', 'la', 'ma', 'na', 'nga', 'pa', 'sa', 'ta', 'wa', 'ya']\n",
    "\n",
    "# Dynamically add compound labels that have no diacritics\n",
    "compound_no_kudlit = df[\n",
    "    (df['top_kudlit'] == 0) &\n",
    "    (df['bottom_kudlit'] == 0) &\n",
    "    (df['cross_under'] == 0)\n",
    "]['label'].str.replace('-', '_').unique().tolist()\n",
    "\n",
    "# Combine hardcoded and dynamic no-kudlit-valid list\n",
    "no_kudlit_valid = set(no_kudlit_valid) | set(compound_no_kudlit)\n",
    "\n",
    "# Counters\n",
    "valid_top_kudlit = 0\n",
    "valid_bottom_kudlit = 0\n",
    "valid_cross_kudlit = 0\n",
    "vowel_single_letter_total = 0\n",
    "no_kudlit_total = 0\n",
    "\n",
    "unmatched_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    label = row['label'].replace('-', '_')  # preserve compound syllables\n",
    "    parts = label.split('_')\n",
    "\n",
    "    matched = False\n",
    "\n",
    "    # Check for valid top kudlit (e/i only)\n",
    "    for part in parts:\n",
    "        if any(part.endswith(v) for v in top_vowel_suffixes):\n",
    "            if row['top_kudlit'] > 0:\n",
    "                valid_top_kudlit += 1\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "    # Check for valid bottom kudlit (o/u only)\n",
    "    for part in parts:\n",
    "        if any(part.endswith(v) for v in bottom_vowel_suffixes):\n",
    "            if row['bottom_kudlit'] > 0:\n",
    "                valid_bottom_kudlit += 1\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "    # Check for valid cross under consonants\n",
    "    for part in parts:\n",
    "        if part in cross_consonants and row['cross_under'] > 0:\n",
    "            valid_cross_kudlit += 1\n",
    "            matched = True\n",
    "            break\n",
    "\n",
    "    # Count single-letter vowel characters\n",
    "    if len(parts) == 1 and parts[0] in ['a', 'e', 'i', 'o', 'u', 'o_u', 'e_i']:\n",
    "        vowel_single_letter_total += 1\n",
    "        matched = True\n",
    "\n",
    "    # Check for no kudlit (valid base characters only)\n",
    "    if row['top_kudlit'] == 0 and row['bottom_kudlit'] == 0 and row['cross_under'] == 0:\n",
    "        if all(part in no_kudlit_valid for part in parts):\n",
    "            no_kudlit_total += 1\n",
    "            matched = True\n",
    "\n",
    "    # Track unmatched rows\n",
    "    if not matched:\n",
    "        unmatched_rows.append(row)\n",
    "\n",
    "# âœ… Summary\n",
    "kudlit_summary_filtered = pd.DataFrame({\n",
    "    \"Type\": [\n",
    "        \"Top Kudlit (Valid e/i)\",\n",
    "        \"Bottom Kudlit (Valid o/u)\",\n",
    "        \"Cross Kudlit (bâ€“y only)\",\n",
    "        \"Vowel Characters (Single-letter)\",\n",
    "        \"No Kudlit (a, ba, ka...)\"\n",
    "    ],\n",
    "    \"Count\": [\n",
    "        valid_top_kudlit,\n",
    "        valid_bottom_kudlit,\n",
    "        valid_cross_kudlit,\n",
    "        vowel_single_letter_total,\n",
    "        no_kudlit_total\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nâœ… Kudlit Summary (Strict Filter with Enhancements):\")\n",
    "print(kudlit_summary_filtered)\n",
    "\n",
    "# âš ï¸ Unmatched analysis\n",
    "unmatched_df = pd.DataFrame(unmatched_rows)\n",
    "total_unmatched = len(unmatched_df)\n",
    "print(f\"\\nâš ï¸ Total Unmatched Entries: {total_unmatched}\")\n",
    "\n",
    "if total_unmatched > 0:\n",
    "    print(\"\\nðŸ§© Top 20 Unmatched Labels:\")\n",
    "    print(unmatched_df['label'].value_counts().head(20))\n",
    "\n",
    "    print(\"\\nðŸ”§ Kudlit Summary in Unmatched Entries:\")\n",
    "    print(unmatched_df[['top_kudlit', 'bottom_kudlit', 'cross_under']].sum())\n",
    "\n",
    "# ðŸ“Š Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=kudlit_summary_filtered, x=\"Count\", y=\"Type\", palette=\"rocket\")\n",
    "\n",
    "for i, row in kudlit_summary_filtered.iterrows():\n",
    "    plt.text(row['Count'] + 0.5, i, str(row['Count']), va='center', fontsize=10)\n",
    "\n",
    "plt.title(\"Filtered Kudlit and Vowel Counts (Strict Rules)\", fontsize=16)\n",
    "plt.xlabel(\"Total Count\", fontsize=12)\n",
    "plt.ylabel(\"Type\", fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
